backend {
  default = "Local"
  providers {

    Local {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        max-concurrent-workflows = 1
        concurrent-job-limit = 2

        filesystems {
          local {
            localization: [
              "hard-link", "soft-link", "copy"
            ]
          }
        }
      }
    }

    Docker {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        run-in-background = true
        runtime-attributes = "String docker"
        submit-docker = "docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"
      }
    }
    
    singularity {
         # The backend custom configuration.
         actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactor"  
         config {
	           max-concurrent-workflows = 1
	           concurrent-job-limit = 1
             run-in-background = true
             runtime-attributes = """
               String? docker
             """
             submit-docker = """
               export SINGULARITY_CACHEDIR=/data1/aafgarci/cris/.singularity/docker                                                                           
               export SINGULARITY_TMPDIR=/data1/aafgarci/cris/.singularity/docker                                                                             
               export SINGULARITY_LOCALCACHEDIR=/data1/aafgarci/cris/.singularity/docker
               singularity exec --bind ${cwd}:${docker_cwd} docker://${docker} bash ${docker_cwd}/execution/script
             """
         }
     }

    slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      config {
        max-concurrent-workflows = 1
	      # number of jobs
        concurrent-job-limit = 2
        runtime-attributes = """
        # cpu-per-task (max 20)
        Int cpu
        # time
        String time
        String? docker
        String? mem
        """

        submit-docker = """
        # Ensure singularity is loaded if it's installed as a module
        module --ignore-cache load singularity
        export OMP_NUM_THREADS=1
        export MKL_NUM_THREADS=1
        export OMP_PLACES=threads
        export OMP_PROC_BIND=spread

        # Add here docker hub info if there are private repos

        # Submit the script to SLURM
        sbatch \
          --partition=SP2 \
          --ntasks=1 \
          --cpus-per-task=${cpu} \
          ${mem} \
          --time=${time} \
          -J ${job_name} \
          -D ${cwd} \
          -o ${cwd}/execution/stdout \
          -e ${cwd}/execution/stderr \
          --wrap "singularity exec --bind ${cwd}:${docker_cwd} docker://${docker} bash ${docker_cwd}/execution/script"
        """

        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"
      }
    }

    SGE {
      config {
        # ... other configuration
        submit-docker = """
        qsub \
            -terse \
            -V \
            -b n \
            -N ${job_name} \
            -wd ${cwd} \
            -o ${out}.qsub \
            -e ${err}.qsub \
            -l docker,docker_images="${docker}"
            -xdv ${cwd}:${docker_cwd}
            ${script}
        """

        job-id-regex = "(\\d+)"
        kill = "qdel ${job_id}"
        check-alive = "qstat -j ${job_id}"
      }
    }

  }
}

database {
  profile = "slick.jdbc.MySQLProfile$"
  db {
    driver = "com.mysql.cj.jdbc.Driver"
    url = "jdbc:mysql://127.0.0.1:3307/cromwell?rewriteBatchedStatements=true&useSSL=false"
    user = "root"
    password = "1234"
    connectionTimeout = 5000
  }
}

call-caching {
  enabled = true
  invalidate-bad-cache-results = true
}

